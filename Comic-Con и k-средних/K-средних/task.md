### K-means

В данном уроке представлена задача кластеризации - разбиения выборки на непересекающиеся множества, объекты которых схожи между собой и отличаются от объектов других множеств. Для нашей задаче объектами будут являться точки, а их характеристиками - значения трех цветовых компонент. Центры подобных множеств будут определять цвета, на которые будут заменены их элементы на изображении. Так, несколько различных оттенков красного, от яркого до бордового, могут быть объединены в один усредненный красный.

Алгоритм кластеризации с помощью k-средних (k-means algorithm) - вид обучения без учителя, применяемый в случае, если группы, получаемые в результате классификации (кластеры) неизвестны. Мы не можем заранее сказать, в какие цвета мы хотим перекрасить изображение, алгоритм определит наиболее подходящие за нас.
Задача этого алгоритма - разбить выборку на `k` групп.

Алгоритм итеративно присваивает каждую из точек выборки одной из `k` групп, основываясь на предоставленных признаках. Кластеры образуются из точек со схожими признаками (в нашем случае - цветами).

В алгоритме применяется итеративное улучшение результата. На вход подаются количество кластеров и набор данных, содержащий признаки каждой из точек (в данном случае - значения красного, синего и зеленого каналов). Алгоритм начинает с первоначального определения `k` центроидов, которые могут быть сгенерированы случайно, или же наугад выбраны из входного набора данных. [Центроид](https://ru.wikipedia.org/wiki/%D0%91%D0%B0%D1%80%D0%B8%D1%86%D0%B5%D0%BD%D1%82%D1%80) это предполагаемый геометрический центр кластера. На данном этапе вовсе не обязательно, чтобы он был близок к настоящему центру, хоть это и может улучшить работу алгоритма. После этого итеративно повторяются два шага:

1. Шаг распределения точек. На данном этапе каждой точке присваивается кластер с ближайшим центроидом. Более формально:

$$c_i = \underset{{c \in 1\dots k}}{\arg\min}  \rho(x_i, \mu_c)$$

где
- $c_i$ -- центр кластера, присвоенный точке $x_i$
- $\rho(x_i, \mu_c)$ -- расстояние между точкой $x_i$ и центром кластера $\mu_c$
- $\mu_{c}$ -- центр кластера

2. Шаг обновления центроидов. На данном этапе происходит перерасчет центроидов как среднего среди точек, присвоенных их кластерам.

$$ {\mu_{c} = \frac{\sum\limits_{j=1,\dots, n} [c_i = c] x_i^j}{\sum\limits_{c_i = c} 1} } $$


Алгоритм повторяет шаги один и два, пока не будет достигнуто условие останова: на какой-то итерации ни одна из точек не изменит свой кластер, будет достигнута минимальная сумма расстояний или будет пройдено некое предельное количество итераций.
При наличии данных условий алгоритм гарантированно сходится. Чем более строгие условия заданы, тем дольше алгоритм будет производить вычисления. Условия стоит варьировать и если производительность недостаточна - ограничить количество итераций. Также возможен пересмотр изначальной задачи - к примеру, построение 4 кластеров вместо 8.

Стоит учитывать, что на первом шаге может образоваться кластер, которому не принадлежит ни одна точка. Это может быть следствием неудачных изначальных центроидов или слишком большого k. Такие случаи необходимо отдельно обрабатывать на втором шаге, чтобы избежать ошибки при вычислении их среднего. Здесь возможны различные подходы, к примеру присвоение пустому кластеру случайной точки, или точки, наиболее удаленной от центра наибольшего кластера. 

При вычислении удаленности точек в задаче используется [евклидова метрика](https://ru.wikipedia.org/wiki/%D0%95%D0%B2%D0%BA%D0%BB%D0%B8%D0%B4%D0%BE%D0%B2%D0%B0_%D0%BC%D0%B5%D1%82%D1%80%D0%B8%D0%BA%D0%B0), однако, в зависимости от условий задачи может применятся любая другая. К примеру, задача о кластеризации текстов могла бы использовать [расстояние Левенштейна](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D1%81%D1%81%D1%82%D0%BE%D1%8F%D0%BD%D0%B8%D0%B5_%D0%9B%D0%B5%D0%B2%D0%B5%D0%BD%D1%88%D1%82%D0%B5%D0%B9%D0%BD%D0%B0).


### Задание

Реализуйте функцию, `k_means(X, n_clusters, distance_metric)`, которая принимает матрицу $X$ размерности
`(n_samples, n_features)`, количество кластеров, на которые мы хотим разбить изображение и метрику. 

Результатом работы функции является пара из вектора размера `n_samples`, где в $i$-й ячейке содержится кластер,
соответствующий $i$-му пикселю, и вектор размера `(n_clusters)` с центрами кластеров.

При выполнении задания может пригодиться функция [numpy.sum](https://numpy.org/doc/1.18/reference/generated/numpy.sum.html), вычисляющая сумму элементов массива.