Скорость работы данного алгоритма весьма сильно зависит от количества начальных кластеров. Попробуйте запустить программу для 4 или 16 цветов и увидите, насколько меняется время выполнения. 

Другая особенность метода - чувствительность к начальному выбору центров, не всегда случайно отобранные центроиды дают удовлетворительный результат кластеризации, иногда при их неудачном расположении можно наблюдать артефакты, в нашем случае части картинки будут раскрашены в неожиданные цвета. Этот эффект можно наблюдать, если несколько раз запустить алгоритм для 4 кластеров. Этот недостаток устраняется последовательными изменениями в методе выбора начальных кластеров и выборе наиболее подходящего.

Описанный нами алгоритм реализован в [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html). При его использовании задаются параметры, которые мы изучили во время урока - количество кластеров, количество пробных запусков с разными начальными кластерами, допустимая ошибка при схождении точек, максимальное количество итераций.

Развитием идеи алгоритма **k-средних** является [k-means++](https://ru.wikipedia.org/wiki/K-means%2B%2B), отличающийся как раз стадией нахождения начальных значений кластеров.

Еще одной модификацией является алгоритм [X-means, eng.](https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set#:~:text=In%20statistics%20and%20data%20mining,criterion%20(BIC)%20is%20reached.), в котором на вход алгоритм получает диапазон возможного количества кластеров, запускается для каждого из возможных и определяет наибольший результат, согласно заявленной метрике качества.

Также алгоритм используется в более сложных задачах машинного обучения, к примеру, в [нейронной сети Кохонена](http://www.machinelearning.ru/wiki/index.php?title=%D0%9D%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%81%D0%B5%D1%82%D1%8C_%D0%9A%D0%BE%D1%85%D0%BE%D0%BD%D0%B5%D0%BD%D0%B0).