### Выбор значения K

При `k = 1` алгоритм ближайшего соседа неустойчив к шумовым выбросам: он даёт ошибочные классификации не только
на объектах-выбросах, но и на ближайших к ним объектах других классов.

При `k = ` размеру выборки, наоборот, алгоритм чрезмерно устойчив и вырождается в константу.

Таким образом, крайние значения `k` нежелательны.

На практике оптимальное значения параметра `k` определяют по критерию скользящего контроля с исключением объектов по одному:
${LOO(k, X^l) = \sum\limits_{i=1}^l [a(x_i; X^l \backslash {x_i}, k) \neq y_i] \rightarrow \min\limits_k}$

### Задание

Реализуйте функцию для выбора оптимального значения k по методу
LOO (leave-one-out) кросс-валидации. Функция должна принимать обучающую выборку и функцию расстояния:
      
      def loocv(X_train, y_train, dist):
          # ...
          return opt_k

Оцените точность и полноту предсказаний классификатора с оптимальным k и двумя любыми функциями расстояния.

Правда ли, что все вина одинаковые?
